{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "hf_token = os.environ['HF_TOKEN']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import (\n",
    "    WhisperProcessor, \n",
    "    WhisperForConditionalGeneration\n",
    ")\n",
    "\n",
    "import librosa\n",
    "from datasets import load_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_audio_data(data_path, sr=16000):\n",
    "    signal, _ = librosa.load(data_path, sr=sr)\n",
    "    return signal\n",
    "\n",
    "\n",
    "class Transcription:\n",
    "    def __init__(self, model_ckpt, sr):\n",
    "        self.processor = WhisperProcessor.from_pretrained(model_ckpt, language=\"en\", task=\"transcribe\")\n",
    "        self.model = WhisperForConditionalGeneration.from_pretrained(model_ckpt)\n",
    "        self.model.config.forced_decoder_ids = None\n",
    "\n",
    "        self.sampling_rate = sr\n",
    "\n",
    "    def transcribe(self, signal):    \n",
    "        input_feature = self.processor(signal, sampling_rate=self.sampling_rate, return_tensors=\"pt\").input_features\n",
    "        # generate token ids\n",
    "        predicted_ids = self.model.generate(input_feature)\n",
    "        # decode token ids to text\n",
    "        transcription = self.processor.batch_decode(predicted_ids, skip_special_tokens=True)\n",
    "        return transcription"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "whisper_ckpt = \"openai/whisper-small\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_path = \"data/audio.wav\"\n",
    "signal = load_audio_data(data_path=data_path, sr=16000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n"
     ]
    }
   ],
   "source": [
    "transcription = Transcription(model_ckpt=whisper_ckpt, sr=16000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Due to a bug fix in https://github.com/huggingface/transformers/pull/28687 transcription using a multilingual Whisper will default to language detection followed by transcription instead of translation to English.This might be a breaking change for your use case. If you want to instead always translate your audio to English, make sure to pass `language='en'`.\n"
     ]
    }
   ],
   "source": [
    "audio_text = transcription.transcribe(signal=signal)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[' अगा जुता तेज वा नहीं तो अजाम में भी तोड़ा सा लड़ा प्राद प्रद प्रद प्रद प्रद प्रद प्रद प्रद प्रद प्रद प्रद प्रद प्रद प्रद प्रद प्रद प्रद प्रद प्रद प्रद प्रद प्रद प्रद प्रद प्रद प्रद प्रद प्रद प्रद प्रद प्रद प्रद प्रद प्रद प्रद प्रद प्रद प्रद प्रद प्रद प्रद प्रद प्रद प्रद प्रद प्रद प्रद प्रद प्रद प्रद प्रद प्रद प्रद प्रद प्रद प्रद प्रद प्रद प्रद प्रद प्रद प्रद प्रद प्रद प्']"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "audio_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "whisper_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
